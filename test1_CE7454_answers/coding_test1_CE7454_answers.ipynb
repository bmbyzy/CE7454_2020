{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE7454 : Deep Learning for Data Science\n",
    "##Â Xavier Bresson\n",
    "\n",
    "\n",
    "## Coding Test 1\n",
    "Date: October 7th, 2020<br>\n",
    "\n",
    "*Instructions* <br>\n",
    "Name: Do not forget to add your name to the notebook file \"coding_test1_CE7454_YOUR_NAME.ipynb\".<br>\n",
    "Questions: This notebook has 10 questions.<br>\n",
    "Answers: Write the answers to each question in this notebook.<br>\n",
    "Type: This test is individual and open-book.<br>\n",
    "Grading: 1 point for each question.<br>\n",
    "Delivery: Upload your notebook to https://drive.google.com/drive/folders/1Owos8IyA2Mh2PGvRlTEJZuNmR7sJOpx-  by 6:20pm. <br>\n",
    "Remark: **If certain conditions of the questions (for eg. hyperparameter values) are not stated, you are free to choose anything you want.**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TT3HcmXNhNxp"
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Create a PyTorch tensor $x$ of type FloatTensor, size [5, 2, 7] and filled with random numbers. Print tensor $x$ and its type. Convert the same tensor $x$ to type LongTensor and print its value and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1600109702676,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "vH-tgwa9gf4L",
    "outputId": "22855a52-17af-4e45-d011-3edc6d8f5fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9027, 0.2811, 0.3214, 0.8193, 0.4659, 0.9217, 0.7292],\n",
      "         [0.7186, 0.1758, 0.5782, 0.4089, 0.7382, 0.6527, 0.1410]],\n",
      "\n",
      "        [[0.1906, 0.3043, 0.8819, 0.4505, 0.5401, 0.0906, 0.1059],\n",
      "         [0.9855, 0.4273, 0.5631, 0.5184, 0.2020, 0.5849, 0.5355]],\n",
      "\n",
      "        [[0.6341, 0.4142, 0.5412, 0.5758, 0.1747, 0.8109, 0.8266],\n",
      "         [0.5400, 0.2497, 0.2317, 0.2189, 0.3120, 0.2294, 0.0174]],\n",
      "\n",
      "        [[0.2345, 0.4870, 0.8494, 0.4145, 0.7121, 0.5540, 0.0606],\n",
      "         [0.6180, 0.6153, 0.5141, 0.7828, 0.0452, 0.4175, 0.6792]],\n",
      "\n",
      "        [[0.5229, 0.9023, 0.0013, 0.9073, 0.6936, 0.3938, 0.5412],\n",
      "         [0.3752, 0.4362, 0.1190, 0.8652, 0.5501, 0.5963, 0.0562]]])\n",
      "torch.FloatTensor\n",
      "tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]]])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "# YOUR CODE HERE\n",
    "x = torch.rand(5,2,7) \n",
    "print(x) \n",
    "print(x.type()) \n",
    "\n",
    "x = x.long() \n",
    "print(x) \n",
    "print(x.type()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute and print the matrix product of matrices A and B given below.\n",
    "\n",
    "Compute and print the element-wise product of matrices C and D given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "A=torch.ones(2,3)\n",
    "B=torch.ones(3,2)\n",
    "C=torch.ones(2,2)\n",
    "D=torch.ones(2,2)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(torch.mm(A,B))\n",
    "print(C*D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3tPn7qa2sLk"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Given a minibatch $x$ of color images represented by a tensor of size (100, 3, 28, 28), with 3 color channels (red, green and blue), a grid domain of 28 pixels by 28 pixels, and 100 images in the minibatch. \n",
    "\n",
    "Transform the tensor $x$ into a vector and print its size.\n",
    "\n",
    "Transform back the vector to a tensor of size (100, 3, 28, 28) and print its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 833,
     "status": "ok",
     "timestamp": 1600108253961,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "djho9-rx3V6Z",
    "outputId": "a7e1e68a-8ce3-427f-8e11-a394c8826bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([235200])\n",
      "torch.Size([100, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "x = torch.rand(100,3,28,28) # given minibatch of color images \n",
    "\n",
    "# YOUR CODE HERE\n",
    "vectorized_x = x.view(235200) # 28*28*3*100 = 235200\n",
    "print(vectorized_x.size())\n",
    "\n",
    "original_x = vectorized_x.view(100,3,28,28)\n",
    "print(original_x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5LNc-Fo7mT1"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Consider a minibatch $s$ of scores of size (100,5) with 5 classes and 100 data points. Convert the scores into probabilities with the softmax operator. Print the scores and the probabilities for the 10th data point (reminder: 1st data point is indexed by 0). \n",
    "\n",
    "Implement a Python function that returns the indices of the classes corresponding to the highest probability for each data in the minibatch. Note that the 5 classes are indexed with integer values $\\{0,1,2,3,4\\}$. Print the index of the highest probability for the 10th data point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1600143105845,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "L67NCs9r7myO",
    "outputId": "ff9a3273-bb24-4cb8-e113-b26ec3bafeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7123,  4.3702,  0.1516,  1.4458,  4.0933])\n",
      "tensor([0.0034, 0.5456, 0.0080, 0.0293, 0.4137])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "s = torch.FloatTensor(100,5).uniform_(-1,5)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "prob = torch.softmax(s, dim=1)\n",
    "print(s[10-1,:])\n",
    "print(prob[10-1,:])\n",
    "\n",
    "def return_max_index(prob):\n",
    "    index_max_prob = torch.argmax(prob, dim=1)\n",
    "    return index_max_prob\n",
    "index_max_prob = return_max_index(prob)\n",
    "print(index_max_prob[10-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZTCUwqn9uYl"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Implement the activation function $$\\sigma(x)=\\frac{2}{2+e^{-x}}$$ as a Python function.\n",
    "\n",
    "Print the activation values of the input tensor x1=$[-4.5,1.2,0.0,6.2]$ with function $\\sigma$. \n",
    "\n",
    "Compute the analytical derivative of $\\sigma$ and implement it as a Python function. \n",
    "\n",
    "$$\\sigma'(x)=\\textrm{to be computed}$$\n",
    "\n",
    "$$\\sigma'(x)=\\frac{2e^{-x}}{(2+e^{-x})^2} \\quad\\textrm{ SOLUTION}$$\n",
    "\n",
    "Print the values of the input tensor x2=$[2.3,-1.9,-3.4,6.2]$ with function $\\sigma'$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1943,
     "status": "ok",
     "timestamp": 1600110208955,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "a7MpmJqn9u1N",
    "outputId": "9bd76404-e992-4de6-c145-66b2d28bab86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0217, 0.8691, 0.6667, 0.9990])\n",
      "tensor([0.0455, 0.1772, 0.0587, 0.0010])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([-4.5,1.2,0.0,6.2])\n",
    "x2 = torch.Tensor([2.3,-1.9,-3.4,6.2])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return 2/ (2 + torch.exp(-x))\n",
    "print(sigma(x1))\n",
    "\n",
    "def derivative_sigma(x):\n",
    "    return 2*torch.exp(-x)/ (2+torch.exp(-x))**2\n",
    "print(derivative_sigma(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_dDEN-vne48"
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a 2-layer MLP with the non-linear activation function $\\sigma$ from Question 5. The output score of the network is defined as\n",
    "\n",
    "$$s = W_2\\sigma(W_1 x + b_1)+b_2$$\n",
    "\n",
    "The size of tensor $x$ is 2 and the size of tensor $s$ is 3.\n",
    "\n",
    "Tensor $W_1$ is a matrix of ones and size (10,2) and tensor $W_2$ is a matrix of ones and size (3,10). \n",
    "\n",
    "Tensors $b_1$ and $b_2$ are vectors of zeros with their sizes constrained by $W_1$ and $W_2$.\n",
    "\n",
    "Print the output tensor $s$ for the input $x=[2.3,-1.4]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1600107092190,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "ZwCjd9Clgjnx",
    "outputId": "3a6d4b04-ab2d-49a9-94a6-6ec527548154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.3106, 8.3106, 8.3106], grad_fn=<AddBackward0>) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.Tensor([2.3,-1.4])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return 2/ (2 + torch.exp(-x))\n",
    "\n",
    "class two_layer_MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(two_layer_MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden_features)\n",
    "        self.linear2 = nn.Linear(hidden_features, out_features)\n",
    "        self.linear1.weight.data.fill_(1.0)\n",
    "        self.linear1.bias.data.fill_(0.0)\n",
    "        self.linear2.weight.data.fill_(1.0)\n",
    "        self.linear2.bias.data.fill_(0.0)\n",
    "    def forward(self, x):\n",
    "        y1 = self.linear1(x)\n",
    "        y2 = sigma(y1)\n",
    "        s = self.linear2(y2)\n",
    "        return s\n",
    "\n",
    "net = two_layer_MLP(2,10,3)\n",
    "s = net(x)\n",
    "print(s,s.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fAm4Cmrb6z5"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Given a minibatch $s=[ [5.2,-1.2], [-1.0,4.0], [-1,2] ]$ of scores of three data points and two classes, implement and compute the mean cross entropy for the labels $[0,1,1]$.\n",
    "\n",
    "As a reminder, the definition of the mean cross entropy loss is \n",
    "\n",
    "$$ L = -\\frac{1}{N}\\sum_{i=1}^N \\log \\Big(\\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)$$\n",
    "\n",
    "where $cl($i$)$ is the class index of the $i^{th}$ training data and $p^{(i)}$ is the probability vector computed by the network (using the score vector).\n",
    "\n",
    "Note that your implementation of the cross entropy cannot use the PyTorch function 'nn.CrossEntropyLoss'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0190)\n",
      "tensor(0.0190)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "s = torch.Tensor( [ [5.2,-1.2], [-1.0,4.0], [-1,2] ] )\n",
    "label = torch.LongTensor([0,1,1])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "p = torch.softmax(s, dim=1)\n",
    "log_prob = -torch.log(p)\n",
    "mean_cross_entropy = log_prob[torch.arange(3),label].mean()\n",
    "print(mean_cross_entropy)\n",
    "print(nn.CrossEntropyLoss()(s,label)) # double checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Implement a new class for the sigma function $\\sigma$ defined in Question 5. Precisely, define explicitely the forward pass and the backward pass for this new class. Hint: https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html\n",
    "\n",
    "Print the output value $y=\\sigma(x)$ for the tensor $x=[1.6,-1.2,0.0,4.0]$.\n",
    "\n",
    "Consider the loss to be \n",
    "\n",
    "$$ L = \\frac{1}{m}\\sum_{j=1}^m y_j^2,\\quad y_j=\\sigma(x_j)$$\n",
    "\n",
    "where $x_1=1.6, x_2=-1.2, x_3=0.0, x_4=4.0$.\n",
    "\n",
    "Print the gradient value $\\frac{dL}{dx}$ for $x=[1.6,-1.2,0.0,4.0]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9083, 0.3759, 0.6667, 0.9909], grad_fn=<sigmaBackward>)\n",
      "tensor([0.0378, 0.0441, 0.0741, 0.0045])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "x = torch.Tensor([1.6,-1.2,0.0,4.0])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class sigma(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return 2/ (2 + torch.exp(-x))\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        local_derivative = 2*torch.exp(-x)/ (2+torch.exp(-x))**2\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input = grad_output* local_derivative\n",
    "        return grad_input\n",
    "\n",
    "sigma_fc = sigma.apply\n",
    "x = x.requires_grad_()\n",
    "y = sigma_fc(x)\n",
    "print(y)\n",
    "\n",
    "loss = (y**2).mean()\n",
    "loss.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Implement a class of 3-layer MLP with ReLU activation :\n",
    "\n",
    "$$s = W_3\\textrm{ ReLU}(W_2\\textrm{ ReLU}(W_1 x + b_1)+b_2)+b_3)$$\n",
    "\n",
    "Instantiate a network with 784 as input dimension, 50 as hidden dimension and 10 as output dimension.\n",
    "\n",
    "During training, only the last linear layer will be trained (the first two linear layers will not be trained and will keep the same initial values during training). \n",
    "\n",
    "Use 10 epochs to train the network with batch size 100 and learning rate 0.01. Print the loss and error of classification of the training set after 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0  loss= 2.300812317530314  error= 87.32666656374931\n",
      "epoch= 1  loss= 2.295027406613032  error= 87.53499990701675\n",
      "epoch= 2  loss= 2.290812224149704  error= 88.30833312869072\n",
      "epoch= 3  loss= 2.2869838837782543  error= 87.24833328525226\n",
      "epoch= 4  loss= 2.2832719520727793  error= 85.53000021974245\n",
      "epoch= 5  loss= 2.279603095849355  error= 83.49333370725314\n",
      "epoch= 6  loss= 2.2759684161345164  error= 82.12666707237561\n",
      "epoch= 7  loss= 2.272345388730367  error= 80.03000003099442\n",
      "epoch= 8  loss= 2.268751895427704  error= 78.80166686574618\n",
      "epoch= 9  loss= 2.2651789593696594  error= 76.64833350976308\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "data_path=check_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class three_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(three_layer_MLP , self).__init__()\n",
    "        self.layer1 = nn.Linear(  input_size, hidden_size )\n",
    "        self.layer2 = nn.Linear(  hidden_size, hidden_size )\n",
    "        self.layer3 = nn.Linear(  hidden_size, output_size )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        score = self.layer3(x)\n",
    "        return score\n",
    "\n",
    "net = three_layer_MLP(784,50,10)\n",
    "\n",
    "params_to_update = []\n",
    "params_to_update.append(net.layer3.weight)\n",
    "params_to_update.append(net.layer3.bias)\n",
    "optimizer=torch.optim.SGD( params_to_update , lr=0.01 )\n",
    "\n",
    "bs = 100\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(60000)\n",
    "    for count in range(0,60000,bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        loss = criterion( scores , minibatch_label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    print('epoch=',epoch, ' loss=', total_loss , ' error=', total_error*100)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Use the class of 3-layer MLP with ReLU activation implemented in Question 9. \n",
    "\n",
    "We will train the network with the quality loss defined as\n",
    "\n",
    "$$ L = \\Big( \\Pi_{i=1}^N \\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)^{1/N}$$\n",
    "\n",
    "where $cl($i$)$ is the class index of the $i^{th}$ training data and $p^{(i)}$ is the probability vector computed by the network.\n",
    "\n",
    "Unlike Question 9, all linear layers will be learned during training. \n",
    "\n",
    "Use 10 epochs to train the network with batch size 25 and learning rate 0.01. Print the loss and error of classification of the training set after 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0  loss= 0.10458569578205545  error= 76.01333390176296\n",
      "epoch= 1  loss= 0.14501238784131903  error= 49.24333333472411\n",
      "epoch= 2  loss= 0.4548073540938397  error= 20.8283333654205\n",
      "epoch= 3  loss= 0.6796698375294606  error= 11.408333711326122\n",
      "epoch= 4  loss= 0.728869843557477  error= 9.44000040491422\n",
      "epoch= 5  loss= 0.7560911426258584  error= 8.473333758612474\n",
      "epoch= 6  loss= 0.7769464354154965  error= 7.681667086978754\n",
      "epoch= 7  loss= 0.7945305673778057  error= 6.905000393589337\n",
      "epoch= 8  loss= 0.8106508443504572  error= 6.311667154232661\n",
      "epoch= 9  loss= 0.8253588288587829  error= 5.76000043998162\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "data_path=check_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class three_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(three_layer_MLP , self).__init__()\n",
    "        self.layer1 = nn.Linear(  input_size, hidden_size )\n",
    "        self.layer2 = nn.Linear(  hidden_size, hidden_size )\n",
    "        self.layer3 = nn.Linear(  hidden_size, output_size )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        score = self.layer3(x)\n",
    "        return score\n",
    "\n",
    "net = three_layer_MLP(784,50,10)\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )\n",
    "bs = 25\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(60000)\n",
    "    for count in range(0,60000,bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices]\n",
    "        minibatch_label= train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        p = torch.softmax(scores,dim=1)\n",
    "        p = p[torch.arange(bs),minibatch_label]\n",
    "        loss = -p.prod()**(1/float(bs))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    print('epoch=',epoch, ' loss=', -total_loss , ' error=', total_error*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNd30TjgREYWyAkV0lT4iX6",
   "name": "CE_7454_coding_test_solution_Vijay.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
